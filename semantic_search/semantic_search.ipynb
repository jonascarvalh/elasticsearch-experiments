{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade elasticsearch tensorflow tensorflow-hub tensorflow-text urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text as tf_text\n",
    "import tensorflow_hub  as tf_hub\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from datasets      import load_dataset\n",
    "from IPython       import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MULTILINGUAL_SENTENCE_ENCODER: str = \"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/multilingual-large/versions/2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Client Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_host:     str   = \"\"\n",
    "es_username: str   = \"\"\n",
    "es_password: str   = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    hosts        = es_host,\n",
    "    basic_auth   = (es_username, es_password),\n",
    "    verify_certs = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download dataset BBC News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news_dataset = load_dataset(\"SetFit/bbc-news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Multilingual Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf_hub.load(MODEL_MULTILINGUAL_SENTENCE_ENCODER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(\"Hello World, Machine Learning ElasticSearch!\")[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create index to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news_index: str = \"bbc_news\"\n",
    "\n",
    "es.indices.create(\n",
    "    index = bbc_news_index,\n",
    "    settings = {\n",
    "        \"number_of_shards\": 2,\n",
    "        \"number_of_replicas\": 1\n",
    "    },\n",
    "    mappings = {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"label\": {\"type\": \"integer\"},\n",
    "            \"label_text\": {\"type\": \"text\"},\n",
    "            \"dataset_type\": {\"type\": \"text\"},\n",
    "            \"text_embeddings\": {\"type\": \"dense_vector\", \"dims\": 512}\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing dataset BBC News on Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_type in bbc_news_dataset:\n",
    "    dataset = bbc_news_dataset[dataset_type]\n",
    "    size    = len(dataset)\n",
    "\n",
    "    for index, item in enumerate(dataset, start=1):\n",
    "        display.clear_output(wait=True)\n",
    "        print(f\"Indexing BBC NEws {dataset_type}, dataset: {index} / {size}\")\n",
    "\n",
    "        document: dict = {\n",
    "            \"text\": item[\"text\"],\n",
    "            \"label\": item[\"label\"],\n",
    "            \"label_text\": item[\"label_text\"],\n",
    "            \"dataset_type\": dataset_type,\n",
    "            \"text_embbedings\": model(item[\"text\"])[0].numpy()\n",
    "        }\n",
    "\n",
    "        es.index(\n",
    "            index = bbc_news_index,\n",
    "            document = document\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query(text: str) -> dict:\n",
    "    query: dict = {\n",
    "        \"scripts_score\": {\n",
    "            \"query\": {\"match_all\": {}},\n",
    "            \"script\": {\n",
    "                \"source\": \"cosineSimilarity(params.text_embbedings, 'text_embeddings') + 1.0\",\n",
    "                \"params\": {\"text_embbedings\": model(text)[0].numpy()}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(text: str) -> None:\n",
    "    query = build_query(text)\n",
    "\n",
    "    result = es.search(index=bbc_news_index, query=query, size=1)\n",
    "    result = result[\"hits\", \"hits\"]\n",
    "\n",
    "    if len(result) == 0:\n",
    "        print(\"No results found...\")\n",
    "        return\n",
    "\n",
    "    result = result[0]\n",
    "\n",
    "    print(f\"Score: {result[\"_score\"]}\")\n",
    "    print(f\"Label: {result[\"_source\"][\"label_text\"]}\")\n",
    "    print(f\"Text:  {result[\"_score\"][\"text\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    semantic_search(\"economic growth\")\n",
    "    semantic_search(\"crescimento econômico\")\n",
    "    semantic_search(\"crecimiento económico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
